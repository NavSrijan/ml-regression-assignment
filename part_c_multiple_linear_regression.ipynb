{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86523ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/cars.csv')\n",
    "\n",
    "# Using multiple features: engine_cc and horsepower\n",
    "X = df[['engine_cc', 'horsepower']].copy()\n",
    "y = df['price_usd'].copy()\n",
    "\n",
    "# Remove missing values\n",
    "mask = ~(X.isna().any(axis=1) | y.isna())\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "print(f\"Dataset size: {len(y)} samples\")\n",
    "print(f\"Features: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462ee355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "X_max = X.max()\n",
    "y_max = y.max()\n",
    "\n",
    "X = X / X_max\n",
    "X = X.values\n",
    "\n",
    "y = y / y_max\n",
    "y = y.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee11b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1's column for intercept\n",
    "n_rows = len(y)\n",
    "X = np.c_[np.ones(n_rows), X]\n",
    "print(X[:5])\n",
    "\n",
    "# Initialize theta - now we have 3 parameters (intercept + 2 features)\n",
    "theta = np.zeros((3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5254f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent\n",
    "epochs = 10000\n",
    "learning_rate = 0.01\n",
    "m = n_rows\n",
    "costs = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    h = X @ theta\n",
    "    error = h - y\n",
    "    cost = (1/(2*m)) * np.sum(np.square(error))\n",
    "    costs.append(cost)\n",
    "    \n",
    "    gradient = (1/m) * (X.T @ error)\n",
    "    theta = theta - learning_rate * gradient\n",
    "\n",
    "print(f\"Final theta: {theta.flatten()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost convergence plot\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(epochs), costs)\n",
    "plt.title('Cost function convergence')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('cost')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039fe2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret coefficients (converting back to original scale)\n",
    "intercept_original = y_max * theta[0].item()\n",
    "coef_engine = (y_max * theta[1].item()) / X_max['engine_cc']\n",
    "coef_hp = (y_max * theta[2].item()) / X_max['horsepower']\n",
    "\n",
    "print(\"\\nMODEL EQUATION:\")\n",
    "print(f\"price = {intercept_original:.2f} + {coef_engine:.4f}*engine_cc + {coef_hp:.4f}*horsepower\")\n",
    "print(f\"\\nIntercept: ${intercept_original:,.2f}\")\n",
    "print(f\"Engine CC coefficient: ${coef_engine:.4f} per cc\")\n",
    "print(f\"Horsepower coefficient: ${coef_hp:.4f} per hp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c8a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation: MSE, RMSE, R²\n",
    "y_pred = (X @ theta) * y_max\n",
    "y_actual = y * y_max\n",
    "\n",
    "# MSE = (1/m) * Σ(y_actual - y_pred)²\n",
    "mse = (1/m) * np.sum(np.square(y_actual - y_pred))\n",
    "\n",
    "# RMSE = √MSE\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# R² = 1 - (SS_res / SS_tot)\n",
    "y_mean = np.mean(y_actual)\n",
    "ss_res = np.sum(np.square(y_actual - y_pred))\n",
    "ss_tot = np.sum(np.square(y_actual - y_mean))\n",
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "print(\"\\nEVALUATION METRICS:\")\n",
    "print(f\"MSE: {mse:,.2f}\")\n",
    "print(f\"RMSE: ${rmse:,.2f}\")\n",
    "print(f\"R²: {r_squared:.6f} ({r_squared*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287dcfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Predicted vs Actual\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_actual, y_pred, alpha=0.5)\n",
    "plt.plot([y_actual.min(), y_actual.max()], \n",
    "         [y_actual.min(), y_actual.max()], \n",
    "         'r--', linewidth=2)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Predicted vs Actual Prices')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9641c8",
   "metadata": {},
   "source": [
    "# Part C: Multiple Linear Regression\n",
    "## Building a multiple linear regression model using mathematical formulas and gradient descent\n",
    "\n",
    "In this notebook, we'll:\n",
    "1. Build a multiple linear regression model using two or more features\n",
    "2. Implement gradient descent manually (no sklearn)\n",
    "3. Interpret coefficients\n",
    "4. Evaluate using MSE, RMSE, and R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca163c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4a955",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('dataset/cars.csv')\n",
    "\n",
    "# Select multiple features for prediction\n",
    "# We'll predict price based on engine_cc and horsepower\n",
    "X = df[['engine_cc', 'horsepower']].copy()\n",
    "y = df['price_usd'].copy()\n",
    "\n",
    "# Remove any rows with missing values\n",
    "mask = ~(X.isna().any(axis=1) | y.isna())\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "print(f\"Dataset size: {len(y)} samples\")\n",
    "print(f\"Features: {list(X.columns)}\")\n",
    "print(f\"\\nFeature statistics:\")\n",
    "print(X.describe())\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b94ef",
   "metadata": {},
   "source": [
    "## Step 2: Feature Scaling\n",
    "Normalize features to ensure gradient descent converges properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78382fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original max values for later interpretation\n",
    "X_max = X.max()\n",
    "y_max = y.max()\n",
    "\n",
    "print(f\"Original feature max values:\")\n",
    "print(X_max)\n",
    "print(f\"\\nOriginal target max value: {y_max}\")\n",
    "\n",
    "# Normalize features by dividing by max\n",
    "X_scaled = X / X_max\n",
    "y_scaled = y / y_max\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_scaled = X_scaled.values\n",
    "y_scaled = y_scaled.values.reshape(-1, 1)\n",
    "\n",
    "print(f\"\\nScaled X shape: {X_scaled.shape}\")\n",
    "print(f\"Scaled y shape: {y_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1c7133",
   "metadata": {},
   "source": [
    "## Step 3: Add Intercept Term\n",
    "Add a column of ones to represent the intercept (θ₀)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column of 1's for intercept term\n",
    "# This allows us to write: y = X @ theta\n",
    "# where theta = [θ₀, θ₁, θ₂, ...]\n",
    "\n",
    "n_rows = len(y_scaled)\n",
    "X_with_intercept = np.c_[np.ones(n_rows), X_scaled]\n",
    "\n",
    "print(f\"X with intercept shape: {X_with_intercept.shape}\")\n",
    "print(f\"\\nFirst 5 rows of X with intercept:\")\n",
    "print(X_with_intercept[:5])\n",
    "\n",
    "# Initialize theta (parameters) - one for intercept + one for each feature\n",
    "n_features = X_with_intercept.shape[1]\n",
    "theta = np.zeros((n_features, 1))\n",
    "print(f\"\\nInitial theta shape: {theta.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fc1d5",
   "metadata": {},
   "source": [
    "## Step 4: Implement Gradient Descent\n",
    "Train the model using gradient descent algorithm\n",
    "\n",
    "**Mathematical formulas:**\n",
    "- Hypothesis: h(x) = X @ θ\n",
    "- Cost function: J(θ) = (1/2m) * Σ(h(x) - y)²\n",
    "- Gradient: ∇J = (1/m) * X^T @ (h(x) - y)\n",
    "- Update rule: θ = θ - α * ∇J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5fcc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 10000\n",
    "learning_rate = 0.01\n",
    "m = n_rows  # Number of training examples\n",
    "\n",
    "# Store cost history for visualization\n",
    "costs = []\n",
    "\n",
    "# Gradient Descent Loop\n",
    "for i in range(epochs):\n",
    "    # Hypothesis: h(x) = X @ theta\n",
    "    h = X_with_intercept @ theta\n",
    "    \n",
    "    # Error between prediction and actual\n",
    "    error = h - y_scaled\n",
    "    \n",
    "    # Cost function: J(θ) = (1/2m) * sum((h(x) - y)²)\n",
    "    cost = (1/(2*m)) * np.sum(np.square(error))\n",
    "    costs.append(cost)\n",
    "    \n",
    "    # Gradient: (1/m) * X^T @ error\n",
    "    gradient = (1/m) * (X_with_intercept.T @ error)\n",
    "    \n",
    "    # Update theta: θ = θ - α * gradient\n",
    "    theta = theta - learning_rate * gradient\n",
    "    \n",
    "    # Print progress every 1000 epochs\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"Epoch {i+1}/{epochs}, Cost: {cost:.6f}\")\n",
    "\n",
    "print(f\"\\nFinal cost: {costs[-1]:.6f}\")\n",
    "print(f\"\\nFinal theta (scaled):\")\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead5401b",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Cost Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77630c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(epochs), costs, linewidth=2)\n",
    "plt.title('Cost Function Convergence', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Cost J(θ)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial cost: {costs[0]:.6f}\")\n",
    "print(f\"Final cost: {costs[-1]:.6f}\")\n",
    "print(f\"Cost reduction: {(costs[0] - costs[-1]):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969ecf7",
   "metadata": {},
   "source": [
    "## Step 6: Interpret Coefficients\n",
    "Convert scaled coefficients back to original scale for interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc73db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients\n",
    "theta_0 = theta[0].item()  # Intercept (scaled)\n",
    "theta_1 = theta[1].item()  # Coefficient for engine_cc (scaled)\n",
    "theta_2 = theta[2].item()  # Coefficient for horsepower (scaled)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MULTIPLE LINEAR REGRESSION MODEL COEFFICIENTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nModel equation (scaled):\")\n",
    "print(f\"price = {theta_0:.6f} + {theta_1:.6f}*engine_cc + {theta_2:.6f}*horsepower\")\n",
    "\n",
    "# Convert back to original scale for interpretation\n",
    "# Since we scaled by max: y_scaled = y/y_max and X_scaled = X/X_max\n",
    "# Original equation: y = intercept + coef1*x1 + coef2*x2\n",
    "# Scaled equation: y/y_max = theta0 + theta1*(x1/x1_max) + theta2*(x2/x2_max)\n",
    "# Therefore: y = y_max*theta0 + (y_max*theta1/x1_max)*x1 + (y_max*theta2/x2_max)*x2\n",
    "\n",
    "intercept_original = y_max * theta_0\n",
    "coef_engine_cc = (y_max * theta_1) / X_max['engine_cc']\n",
    "coef_horsepower = (y_max * theta_2) / X_max['horsepower']\n",
    "\n",
    "print(f\"\\nModel equation (original scale):\")\n",
    "print(f\"price_usd = {intercept_original:.2f} + {coef_engine_cc:.4f}*engine_cc + {coef_horsepower:.4f}*horsepower\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"COEFFICIENT INTERPRETATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nIntercept (θ₀): ${intercept_original:,.2f}\")\n",
    "print(f\"  → Base price when all features are zero\")\n",
    "\n",
    "print(f\"\\nEngine CC Coefficient (θ₁): ${coef_engine_cc:.4f}\")\n",
    "print(f\"  → For every 1 cc increase in engine size,\")\n",
    "print(f\"    price increases by ${coef_engine_cc:.4f} (holding horsepower constant)\")\n",
    "\n",
    "print(f\"\\nHorsepower Coefficient (θ₂): ${coef_horsepower:.4f}\")\n",
    "print(f\"  → For every 1 unit increase in horsepower,\")\n",
    "print(f\"    price increases by ${coef_horsepower:.4f} (holding engine_cc constant)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6683b3",
   "metadata": {},
   "source": [
    "## Step 7: Make Predictions and Calculate Evaluation Metrics\n",
    "Calculate MSE, RMSE, and R² using mathematical formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ed21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on scaled data\n",
    "y_pred_scaled = X_with_intercept @ theta\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "y_pred = y_pred_scaled * y_max\n",
    "y_actual = y_scaled * y_max\n",
    "\n",
    "# Calculate evaluation metrics manually\n",
    "\n",
    "# 1. Mean Squared Error (MSE)\n",
    "# MSE = (1/m) * Σ(y_actual - y_pred)²\n",
    "mse = (1/m) * np.sum(np.square(y_actual - y_pred))\n",
    "\n",
    "# 2. Root Mean Squared Error (RMSE)\n",
    "# RMSE = √MSE\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# 3. R² (Coefficient of Determination)\n",
    "# R² = 1 - (SS_res / SS_tot)\n",
    "# SS_res = Σ(y_actual - y_pred)² (residual sum of squares)\n",
    "# SS_tot = Σ(y_actual - y_mean)² (total sum of squares)\n",
    "y_mean = np.mean(y_actual)\n",
    "ss_res = np.sum(np.square(y_actual - y_pred))\n",
    "ss_tot = np.sum(np.square(y_actual - y_mean))\n",
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL EVALUATION METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nMean Squared Error (MSE): ${mse:,.2f}²\")\n",
    "print(f\"  → Average squared difference between predicted and actual prices\")\n",
    "\n",
    "print(f\"\\nRoot Mean Squared Error (RMSE): ${rmse:,.2f}\")\n",
    "print(f\"  → Average prediction error in original units (USD)\")\n",
    "print(f\"  → On average, predictions are off by ${rmse:,.2f}\")\n",
    "\n",
    "print(f\"\\nR² Score: {r_squared:.6f} ({r_squared*100:.4f}%)\")\n",
    "print(f\"  → Model explains {r_squared*100:.4f}% of the variance in price\")\n",
    "print(f\"  → Closer to 1.0 means better fit\")\n",
    "\n",
    "if r_squared > 0.8:\n",
    "    print(f\"  → This is a STRONG model (R² > 0.8)\")\n",
    "elif r_squared > 0.6:\n",
    "    print(f\"  → This is a MODERATE model (0.6 < R² < 0.8)\")\n",
    "else:\n",
    "    print(f\"  → This is a WEAK model (R² < 0.6)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5f8e6",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Results - Predicted vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cd7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Subplot 1: Predicted vs Actual scatter plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_actual, y_pred, alpha=0.5, s=30)\n",
    "plt.plot([y_actual.min(), y_actual.max()], \n",
    "         [y_actual.min(), y_actual.max()], \n",
    "         'r--', linewidth=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Price (USD)', fontsize=11)\n",
    "plt.ylabel('Predicted Price (USD)', fontsize=11)\n",
    "plt.title('Predicted vs Actual Prices', fontsize=13, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Residuals plot\n",
    "residuals = y_actual - y_pred\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_pred, residuals, alpha=0.5, s=30)\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted Price (USD)', fontsize=11)\n",
    "plt.ylabel('Residuals (Actual - Predicted)', fontsize=11)\n",
    "plt.title('Residual Plot', fontsize=13, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Residual statistics:\")\n",
    "print(f\"Mean residual: ${np.mean(residuals).item():,.2f}\")\n",
    "print(f\"Std residual: ${np.std(residuals).item():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceef53e",
   "metadata": {},
   "source": [
    "## Step 9: 3D Visualization of Regression Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887ecdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3D plot showing the regression plane\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Original data points\n",
    "ax.scatter(X_scaled[:, 0], X_scaled[:, 1], y_scaled, \n",
    "           c='blue', marker='o', alpha=0.5, s=20, label='Actual Data')\n",
    "\n",
    "# Create mesh for regression plane\n",
    "x1_range = np.linspace(X_scaled[:, 0].min(), X_scaled[:, 0].max(), 30)\n",
    "x2_range = np.linspace(X_scaled[:, 1].min(), X_scaled[:, 1].max(), 30)\n",
    "x1_mesh, x2_mesh = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "# Calculate predicted values for the mesh\n",
    "y_mesh = theta[0] + theta[1] * x1_mesh + theta[2] * x2_mesh\n",
    "\n",
    "# Plot regression plane\n",
    "ax.plot_surface(x1_mesh, x2_mesh, y_mesh, \n",
    "                alpha=0.3, cmap='viridis', label='Regression Plane')\n",
    "\n",
    "ax.set_xlabel('Engine CC (scaled)', fontsize=11, labelpad=10)\n",
    "ax.set_ylabel('Horsepower (scaled)', fontsize=11, labelpad=10)\n",
    "ax.set_zlabel('Price (scaled)', fontsize=11, labelpad=10)\n",
    "ax.set_title('Multiple Linear Regression - 3D Visualization', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The plot shows:\")\n",
    "print(\"- Blue points: Actual data points\")\n",
    "print(\"- Colored surface: Regression plane fitted by our model\")\n",
    "print(\"- The plane represents: price = θ₀ + θ₁*engine_cc + θ₂*horsepower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc14a26",
   "metadata": {},
   "source": [
    "## Step 10: Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c7ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some example predictions\n",
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE PREDICTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example 1\n",
    "example_engine_cc = 2000\n",
    "example_horsepower = 150\n",
    "example_scaled = np.array([[1, \n",
    "                           example_engine_cc / X_max['engine_cc'], \n",
    "                           example_horsepower / X_max['horsepower']]])\n",
    "prediction_scaled = example_scaled @ theta\n",
    "prediction = prediction_scaled.item() * y_max\n",
    "\n",
    "print(f\"\\nExample 1:\")\n",
    "print(f\"  Engine CC: {example_engine_cc} cc\")\n",
    "print(f\"  Horsepower: {example_horsepower} hp\")\n",
    "print(f\"  Predicted Price: ${prediction:,.2f}\")\n",
    "\n",
    "# Example 2\n",
    "example_engine_cc = 3500\n",
    "example_horsepower = 250\n",
    "example_scaled = np.array([[1, \n",
    "                           example_engine_cc / X_max['engine_cc'], \n",
    "                           example_horsepower / X_max['horsepower']]])\n",
    "prediction_scaled = example_scaled @ theta\n",
    "prediction = prediction_scaled.item() * y_max\n",
    "\n",
    "print(f\"\\nExample 2:\")\n",
    "print(f\"  Engine CC: {example_engine_cc} cc\")\n",
    "print(f\"  Horsepower: {example_horsepower} hp\")\n",
    "print(f\"  Predicted Price: ${prediction:,.2f}\")\n",
    "\n",
    "# Example 3\n",
    "example_engine_cc = 1500\n",
    "example_horsepower = 100\n",
    "example_scaled = np.array([[1, \n",
    "                           example_engine_cc / X_max['engine_cc'], \n",
    "                           example_horsepower / X_max['horsepower']]])\n",
    "prediction_scaled = example_scaled @ theta\n",
    "prediction = prediction_scaled.item() * y_max\n",
    "\n",
    "print(f\"\\nExample 3:\")\n",
    "print(f\"  Engine CC: {example_engine_cc} cc\")\n",
    "print(f\"  Horsepower: {example_horsepower} hp\")\n",
    "print(f\"  Predicted Price: ${prediction:,.2f}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc3319",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we successfully:\n",
    "\n",
    "1. **Built a multiple linear regression model** from scratch using gradient descent\n",
    "2. **Used mathematical formulas** instead of libraries like sklearn\n",
    "3. **Trained the model** on multiple features (engine_cc and horsepower)\n",
    "4. **Interpreted coefficients** in both scaled and original units\n",
    "5. **Evaluated the model** using:\n",
    "   - **MSE** (Mean Squared Error): Measures average squared error\n",
    "   - **RMSE** (Root Mean Squared Error): Error in original units\n",
    "   - **R²** (Coefficient of Determination): Proportion of variance explained\n",
    "6. **Visualized results** with scatter plots, residuals, and 3D regression plane\n",
    "\n",
    "### Key Mathematical Concepts Used:\n",
    "- **Hypothesis function**: h(x) = θ₀ + θ₁x₁ + θ₂x₂\n",
    "- **Cost function**: J(θ) = (1/2m) * Σ(h(x) - y)²\n",
    "- **Gradient descent**: θ := θ - α * ∇J(θ)\n",
    "- **Matrix form**: h(x) = X @ θ\n",
    "- **Gradient**: ∇J = (1/m) * X^T @ (h(x) - y)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
